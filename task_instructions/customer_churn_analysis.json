{
  "id": "task-instruction-customer-churn",
  "title": "Customer Churn Analysis and Predictive Modeling Guide",
  "category": "data_analysis",
  "intent": "predictive_modeling",
  "keywords": ["customer churn", "predictive model", "at-risk customers", "machine learning", "data analysis", "retention", "classification"],
  "description": "Comprehensive guide for analyzing customer churn data and building predictive models to identify at-risk customers.",
  "content": "# Customer Churn Analysis and Predictive Modeling\n\n## Overview\nCustomer churn analysis involves examining patterns in customer behavior to predict which customers are likely to leave. This guide provides step-by-step instructions for building a robust churn prediction system.\n\n## Phase 1: Data Collection and Preparation\n\n### 1.1 Gather Required Data\n- **Customer Demographics**: Age, gender, location, account tenure\n- **Transaction History**: Purchase frequency, recency, monetary value (RFM analysis)\n- **Engagement Metrics**: Login frequency, feature usage, support tickets\n- **Contract Details**: Subscription type, billing cycle, contract length\n- **Interaction Data**: Email opens, app usage, customer service calls\n\n### 1.2 Data Quality Assessment\n```python\nimport pandas as pd\nimport numpy as np\n\n# Load data\ndf = pd.read_csv('customer_data.csv')\n\n# Check missing values\nmissing_report = df.isnull().sum() / len(df) * 100\nprint(\"Missing value percentages:\")\nprint(missing_report[missing_report > 0])\n\n# Check data types\nprint(df.dtypes)\n\n# Statistical summary\nprint(df.describe())\n```\n\n### 1.3 Feature Engineering\nCreate derived features that capture customer behavior:\n- **Tenure Groups**: Categorize customers by account age\n- **Engagement Score**: Composite metric of activity levels\n- **Value Segments**: RFM-based customer segmentation\n- **Trend Indicators**: Changes in behavior over time\n\n```python\n# Example feature engineering\ndf['days_since_last_purchase'] = (pd.to_datetime('today') - pd.to_datetime(df['last_purchase_date'])).dt.days\ndf['avg_monthly_transactions'] = df['total_transactions'] / df['tenure_months']\ndf['support_ticket_rate'] = df['support_tickets'] / df['tenure_months']\ndf['engagement_trend'] = df['recent_logins'] / df['historical_avg_logins']\n```\n\n## Phase 2: Exploratory Data Analysis\n\n### 2.1 Churn Distribution Analysis\n- Analyze churn rate across different customer segments\n- Identify high-risk periods in customer lifecycle\n- Examine correlation between features and churn\n\n### 2.2 Visualization\n```python\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Churn rate by tenure\nplt.figure(figsize=(10, 6))\nsns.barplot(x='tenure_group', y='churned', data=df)\nplt.title('Churn Rate by Customer Tenure')\nplt.ylabel('Churn Rate')\nplt.show()\n\n# Correlation heatmap\ncorrelation_matrix = df.select_dtypes(include=[np.number]).corr()\nplt.figure(figsize=(12, 8))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\nplt.title('Feature Correlation Matrix')\nplt.show()\n```\n\n## Phase 3: Model Development\n\n### 3.1 Data Preprocessing\n```python\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n\n# Handle categorical variables\nle = LabelEncoder()\nfor col in categorical_columns:\n    df[col] = le.fit_transform(df[col])\n\n# Split data\nX = df.drop(['churned', 'customer_id'], axis=1)\ny = df['churned']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Scale features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n```\n\n### 3.2 Model Selection and Training\nRecommended algorithms for churn prediction:\n- **Random Forest**: Good for interpretability and handling imbalanced data\n- **XGBoost/LightGBM**: High accuracy with proper tuning\n- **Logistic Regression**: Baseline model with probability outputs\n- **Neural Networks**: For complex patterns with large datasets\n\n```python\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, roc_auc_score\n\n# Random Forest\nrf_model = RandomForestClassifier(n_estimators=100, max_depth=10, class_weight='balanced', random_state=42)\nrf_model.fit(X_train_scaled, y_train)\n\n# XGBoost\nxgb_model = XGBClassifier(n_estimators=100, max_depth=6, scale_pos_weight=ratio, random_state=42)\nxgb_model.fit(X_train_scaled, y_train)\n```\n\n### 3.3 Model Evaluation\n```python\nfrom sklearn.metrics import confusion_matrix, precision_recall_curve, auc\n\n# Predictions\ny_pred = rf_model.predict(X_test_scaled)\ny_pred_proba = rf_model.predict_proba(X_test_scaled)[:, 1]\n\n# Metrics\nprint(classification_report(y_test, y_pred))\nprint(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n\n# Feature importance\nimportance_df = pd.DataFrame({\n    'feature': X.columns,\n    'importance': rf_model.feature_importances_\n}).sort_values('importance', ascending=False)\n```\n\n## Phase 4: Deployment and Monitoring\n\n### 4.1 Model Deployment\n- Deploy model as REST API using FastAPI or Flask\n- Implement batch scoring for large customer bases\n- Set up real-time prediction for immediate risk assessment\n\n### 4.2 Monitoring and Maintenance\n- Track model performance metrics over time\n- Set up alerts for model drift\n- Retrain model periodically with new data\n- A/B test retention interventions\n\n## Best Practices\n\n1. **Handle Class Imbalance**: Use techniques like SMOTE, class weights, or threshold adjustment\n2. **Feature Selection**: Use recursive feature elimination or SHAP values\n3. **Cross-Validation**: Use stratified k-fold to ensure robust evaluation\n4. **Interpretability**: Use SHAP or LIME for model explanations\n5. **Business Integration**: Connect predictions to automated retention workflows\n\n## Expected Outcomes\n- Identify customers with >70% churn probability\n- Reduce churn rate by 15-25% through targeted interventions\n- Increase customer lifetime value by prioritizing high-value at-risk customers",
  "estimated_effort": "high",
  "steps": [
    {"step": 1, "action": "Data Collection", "description": "Gather customer demographics, transaction history, and engagement data"},
    {"step": 2, "action": "Data Preparation", "description": "Clean data, handle missing values, and perform feature engineering"},
    {"step": 3, "action": "Exploratory Analysis", "description": "Analyze churn patterns and identify key predictors"},
    {"step": 4, "action": "Model Development", "description": "Train and evaluate multiple classification models"},
    {"step": 5, "action": "Model Selection", "description": "Choose best model based on precision, recall, and AUC"},
    {"step": 6, "action": "Deployment", "description": "Deploy model as API and integrate with business systems"},
    {"step": 7, "action": "Monitoring", "description": "Set up performance tracking and model drift detection"}
  ],
  "related_tasks": ["subscription analysis", "customer segmentation", "retention optimization", "lifetime value prediction"]
}
